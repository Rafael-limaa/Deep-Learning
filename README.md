# üç∑ Classifica√ß√£o da Qualidade de Vinhos com Redes Neurais MLP

Este projeto aplica t√©cnicas de Deep Learning com **Redes Neurais Multicamadas (MLP)** para prever a qualidade de vinhos com base em atributos fisico-qu√≠micos. Utilizamos o [Wine Quality Dataset](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset) dispon√≠vel no Kaggle.

---

## üéØ Objetivo

Construir, treinar e comparar diferentes arquiteturas de redes neurais do tipo MLP (Multi-Layer Perceptron), avaliando o impacto de hiperpar√¢metros como:
- N√∫mero de camadas ocultas
- Quantidade de neur√¥nios por camada
- Fun√ß√£o de ativa√ß√£o
- Tamanho do batch
- Uso de t√©cnicas de regulariza√ß√£o como **Early Stopping**

---

## üß™ Base de Dados

- Fonte: Kaggle ‚Äì [Wine Quality Dataset](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset)
- Tipo: CSV
- Total de amostras: 1.149 registros
- Atributos:
  - 11 vari√°veis independentes (ex: pH, √°lcool, acidez vol√°til)
  - 1 vari√°vel dependente: `quality` (nota de 3 a 8)

---

## üß† Modelos MLP Avaliados

| Modelo | Arquitetura               | Observa√ß√µes                         |
|--------|---------------------------|-------------------------------------|
| 1      | 1 camada oculta (16)      | Arquitetura simples (baseline)      |
| 2      | 2 camadas (32 ‚Üí 16)       | Aprendizado mais profundo           |
| 3      | 2 camadas + batch_size=64 | Varia√ß√£o no tamanho do lote         |
| 4      | 2 camadas + EarlyStopping | Regulariza√ß√£o contra overfitting    |

Todos os modelos utilizam:
- Fun√ß√£o de ativa√ß√£o: `ReLU` (ocultas) e `softmax` (sa√≠da)
- Otimizador: `Adam`
- Perda: `categorical_crossentropy`
- Treino por at√© 50 √©pocas (ou at√© parada antecipada)

---

## ‚öôÔ∏è Tecnologias Utilizadas

- Python 3.10+
- TensorFlow / Keras
- Scikit-learn
- Pandas
- Matplotlib e Seaborn
- Google Colab (ambiente de desenvolvimento)

---

## üìä An√°lises Realizadas

- **Visualiza√ß√£o explorat√≥ria dos dados** (distribui√ß√£o da qualidade, correla√ß√£o, boxplots)
- **Normaliza√ß√£o** dos dados com MinMaxScaler
- **Codifica√ß√£o one-hot** da vari√°vel target
- **Divis√£o em treino e teste (70/30)**
- **Treinamento de m√∫ltiplos modelos MLP**
- **Compara√ß√£o com gr√°ficos de acur√°cia (treino x valida√ß√£o)**
- **Avalia√ß√£o com classifica√ß√£o multiclasse**:
  - Acur√°cia
  - Relat√≥rio de classifica√ß√£o (precision, recall, f1-score)
  - Matriz de confus√£o

---

## üìå Resultados Obtidos

- O modelo com duas camadas ocultas (32 ‚Üí 16 neur√¥nios) + EarlyStopping obteve o melhor desempenho, equilibrando acur√°cia e generaliza√ß√£o.
- A maioria dos erros ocorre entre classes pr√≥ximas (ex: qualidade 5 confundida com 6).
- Adi√ß√µes como batch size e parada antecipada impactaram positivamente na estabilidade do modelo.

---

## üìÅ Estrutura do Projeto

